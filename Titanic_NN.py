{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":12025270,"sourceType":"datasetVersion","datasetId":7565788}],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/shaheemshaik/titanic-nn?scriptVersionId=243077204\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-06-01T14:22:35.125458Z","iopub.execute_input":"2025-06-01T14:22:35.125766Z","iopub.status.idle":"2025-06-01T14:22:36.680551Z","shell.execute_reply.started":"2025-06-01T14:22:35.125726Z","shell.execute_reply":"2025-06-01T14:22:36.679691Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\n\n# Load training data\ntrain_data = pd.read_csv(\"/kaggle/input/titanic2/train.csv\")\n\n# Drop irrelevant columns\ntrain_data = train_data.drop(['Name', 'Ticket', 'Cabin', 'PassengerId'], axis=1)\n\n# Fill missing values in training data\ntrain_data['Age'] = train_data['Age'].fillna(train_data['Age'].median())\ntrain_data['Embarked'] = train_data['Embarked'].fillna(train_data['Embarked'].mode()[0])\n\n# Separate features and label\nX_train = train_data.drop('Survived', axis=1)\ny_train = train_data['Survived']\n\n# One-hot encode categorical columns\nct = ColumnTransformer([\n    (\"encode\", OneHotEncoder(), ['Sex', 'Embarked', 'Pclass'])\n], remainder='passthrough')\n\n# Fit and transform training features\nX_train = ct.fit_transform(X_train)\n\n# Scale features\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T14:26:28.714209Z","iopub.execute_input":"2025-06-01T14:26:28.714549Z","iopub.status.idle":"2025-06-01T14:26:28.736552Z","shell.execute_reply.started":"2025-06-01T14:26:28.714528Z","shell.execute_reply":"2025-06-01T14:26:28.735435Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\n\nmodel = Sequential()\nmodel.add(Dense(32, input_shape=(X_train.shape[1],), activation='relu'))\nmodel.add(Dense(17, activation='relu'))\nmodel.add(Dense(1, activation='sigmoid'))  # Binary output\n\nmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n\n# Train\nmodel.fit(X_train, y_train, epochs=50, batch_size=16, validation_split=0.1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T14:26:38.429249Z","iopub.execute_input":"2025-06-01T14:26:38.429841Z","iopub.status.idle":"2025-06-01T14:26:49.78172Z","shell.execute_reply.started":"2025-06-01T14:26:38.429817Z","shell.execute_reply":"2025-06-01T14:26:49.780984Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"loss, accuracy = model.evaluate(X_train, y_train)\nprint(f\"Train Loss: {loss:.4f}\")\nprint(f\"Train Accuracy: {accuracy:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T14:28:00.859445Z","iopub.execute_input":"2025-06-01T14:28:00.860184Z","iopub.status.idle":"2025-06-01T14:28:01.003261Z","shell.execute_reply.started":"2025-06-01T14:28:00.860163Z","shell.execute_reply":"2025-06-01T14:28:01.00258Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_data = pd.read_csv(\"/kaggle/input/titanic2/test.csv\")\npassenger_ids = test_data['PassengerId']\n\n# Drop irrelevant columns\ntest_data = test_data.drop(['Name', 'Ticket', 'Cabin', 'PassengerId'], axis=1)\n\n# Fill missing values using training data stats\ntest_data['Age'] = test_data['Age'].fillna(data['Age'].median())\ntest_data['Fare'] = test_data['Fare'].fillna(data['Fare'].median())\n# Embarked is usually not missing in test, but just in case:\ntest_data['Embarked'] = test_data['Embarked'].fillna(data['Embarked'].mode()[0])\n\n# Transform using previously fitted transformers\nX_kaggle = ct.transform(test_data)\nX_kaggle = scaler.transform(X_kaggle)\n\n# Predict and convert to binary labels\ny_pred = model.predict(X_kaggle)\ny_pred_binary = (y_pred > 0.5).astype(int).flatten()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T14:29:04.343545Z","iopub.execute_input":"2025-06-01T14:29:04.343873Z","iopub.status.idle":"2025-06-01T14:29:04.472125Z","shell.execute_reply.started":"2025-06-01T14:29:04.343849Z","shell.execute_reply":"2025-06-01T14:29:04.471476Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"submission = pd.DataFrame({\n    'PassengerId': passenger_ids,\n    'Survived': y_pred_binary\n})\nsubmission.to_csv(\"submission_2.csv\", index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T14:30:05.876687Z","iopub.execute_input":"2025-06-01T14:30:05.876986Z","iopub.status.idle":"2025-06-01T14:30:05.883609Z","shell.execute_reply.started":"2025-06-01T14:30:05.876965Z","shell.execute_reply":"2025-06-01T14:30:05.882711Z"}},"outputs":[],"execution_count":null}]}